{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "message=[\n",
    "    HumanMessage(\"Hi! I'm faraz, and I'm a software engineer.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Faraz! ðŸ‘‹ \\n\\nIt's great to hear that you're a software engineer. What kind of software do you enjoy working on?  \\n\\nI'm always interested in learning more about different areas of the field. ðŸ˜„\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 25, 'total_tokens': 81, 'completion_time': 0.101818182, 'prompt_time': 0.00014587, 'queue_time': 0.019314239, 'total_time': 0.101964052}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a7b9c8c6-da31-4722-8a49-112b28a20746-0', usage_metadata={'input_tokens': 25, 'output_tokens': 56, 'total_tokens': 81})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(\"Hi! I'm faraz, and I'm a software engineer.\"),\n",
    "    AIMessage(\"Nice to meet you, Faraz! ðŸ‘‹ \\n\\nIt's great to hear that you're a software engineer. What kind of software do you enjoy working on?  \\n\\nI'm always interested in learning more about different areas of the field. ðŸ˜„\\n\"\n",
    "              ),\n",
    "    HumanMessage(\"What is my name and what do i do\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Faraz, and you are a software engineer. ðŸ˜Š  \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm happy to chat! ðŸ’»  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 98, 'total_tokens': 143, 'completion_time': 0.081818182, 'prompt_time': 0.003439412, 'queue_time': 0.019421325, 'total_time': 0.085257594}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-45f3c252-95e0-4188-ad2f-8b56262fb26b-0', usage_metadata={'input_tokens': 98, 'output_tokens': 45, 'total_tokens': 143})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions={}\n",
    "def getSession(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in sessions:\n",
    "        sessions[session_id] = ChatMessageHistory()\n",
    "    return sessions[session_id]\n",
    "chat_with_history = RunnableWithMessageHistory(model,getSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_with_history.invoke(\n",
    "    HumanMessage(\"Hi, I'm Faraz, and I'm a software engineer.\"),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Faraz, it's nice to meet you!\\n\\nBeing a software engineer myself, I'm always interested to chat with other professionals in the field. What kind of software engineering do you specialize in?  \\n\\nDo you have any interesting projects you're working on right now?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 25, 'total_tokens': 87, 'completion_time': 0.112727273, 'prompt_time': 0.000144419, 'queue_time': 0.022260328, 'total_time': 0.112871692}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9f7c8772-6789-405e-95d9-ccef2d76f7dc-0', usage_metadata={'input_tokens': 25, 'output_tokens': 62, 'total_tokens': 87})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_with_history.invoke(\n",
    "    HumanMessage(\"what is my name and what do i do\"),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"According to our conversation, your name is Faraz and you are a software engineer.  ðŸ˜Š  \\n\\nIs there anything else you'd like to tell me about yourself or your work?  I'm eager to learn more! \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 104, 'total_tokens': 156, 'completion_time': 0.094545455, 'prompt_time': 0.003343635, 'queue_time': 0.019807715, 'total_time': 0.09788909}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0f47f946-d9e6-41c9-9c51-b64bb4b9421f-0', usage_metadata={'input_tokens': 104, 'output_tokens': 52, 'total_tokens': 156})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_with_history.invoke(\n",
    "    HumanMessage(\"what is my name and what do i do\"),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Since I don't have access to any information about you, including your name or occupation, I can't tell you what they are.\\n\\nIs there anything else I can help you with? Perhaps you'd like to play a game or have me write a story? ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 78, 'total_tokens': 140, 'completion_time': 0.112727273, 'prompt_time': 0.005041637, 'queue_time': 0.018596282, 'total_time': 0.11776891}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fdc64535-c46d-43f9-bae7-3d70f7ef98c0-0', usage_metadata={'input_tokens': 78, 'output_tokens': 62, 'total_tokens': 140})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_with_history.invoke(\n",
    "    HumanMessage(\"what is my name and what do i do\"),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Faraz and that you are a software engineer. \\n\\nIs there anything else you'd like to chat about? ðŸ˜Š  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 172, 'total_tokens': 206, 'completion_time': 0.061818182, 'prompt_time': 0.00663399, 'queue_time': 0.018967748, 'total_time': 0.068452172}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4a9560a5-7a78-4870-a127-831db9eb812c-0', usage_metadata={'input_tokens': 172, 'output_tokens': 34, 'total_tokens': 206})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = chat_with_history.invoke(\n",
    "    HumanMessage(\"My name is ahmad and I'm a doctor\"),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's nice to meet you, Ahmad! That's wonderful that you're a doctor. \\n\\nIs there anything I can do for you today, Dr. Ahmad? Perhaps you have a medical question you'd like to discuss (although I'm not a real doctor, so please don't rely on me for medical advice!), or maybe you'd like to talk about something else entirely? ðŸ˜Š \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 158, 'total_tokens': 248, 'completion_time': 0.163636364, 'prompt_time': 0.004942723, 'queue_time': 0.021628754, 'total_time': 0.168579087}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ddd15ea3-3185-45e1-a07e-ae9fa49aaf43-0', usage_metadata={'input_tokens': 158, 'output_tokens': 90, 'total_tokens': 248})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You\\'ve told me your name is Ahmad, and you\\'re a doctor!  It\\'s nice to \"meet\" you, Ahmad. \\n\\nIs there anything I can help you with today?  Perhaps you\\'d like to discuss a medical topic, or maybe you\\'re just looking for a friendly chat?  ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 443, 'total_tokens': 515, 'completion_time': 0.130909091, 'prompt_time': 0.017952495, 'queue_time': 0.021793901000000004, 'total_time': 0.148861586}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4d444b85-74c3-482a-9c82-78dfb5f05241-0', usage_metadata={'input_tokens': 443, 'output_tokens': 72, 'total_tokens': 515})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = chat_with_history.invoke(\n",
    "    HumanMessage(\"what is my name and what do i do\"),\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Faraz and that you are a software engineer.  \\n\\nDo you want to talk about your work as a software engineer? I'm curious to hear more!  ðŸ’»  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 223, 'total_tokens': 268, 'completion_time': 0.081818182, 'prompt_time': 0.008469524, 'queue_time': 0.022567152, 'total_time': 0.090287706}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c4733d2e-5c67-4a88-a8a3-1eea0e089cfe-0', usage_metadata={'input_tokens': 223, 'output_tokens': 45, 'total_tokens': 268})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response = chat_with_history.invoke(\n",
    "    HumanMessage(\"what is my name and what do i do\"),\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an ai assistant to answer the questions Note: answer the questions in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Sri Akaal Faraz Ji!  \\n\\nMain tera AI assistant hun, jo terrak questions Punjabi ch jawab da sakda.  \\n\\nKive kaam kar sakdi aan?  \\n\\n(Hello Faraz! I am your AI assistant who can answer your questions in Punjabi.  \\n\\nHow can I help you?) \\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi I'm Faraz, a software engineer\")],\"language\":\"Punjabi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_history = RunnableWithMessageHistory(chain,getSession,input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_history.invoke({\"messages\":[HumanMessage(content=\"Hi I'm Faraz, a software engineer\")],\"language\":\"Eng\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Faraz!  \\n\\nIt's nice to meet you.  I'm an AI assistant, here to help with any questions or tasks you might have. \\n\\nWhat can I do for you today, as a fellow engineer? ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said your name is Faraz, and you are a software engineer.  \n",
      "\n",
      "Is there anything else I can help you with?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=with_history.invoke({\"messages\":[HumanMessage(content=\"what is my name and what do i do\")],\"language\":\"Eng\"},config=config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    token_counter=model,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    "    strategy=\"last\",\n",
    "    include_system=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an ai assistant to answer the qeston', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Hi! I'm Faraz\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I lik venila ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having Fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an ai assistant to answer the qeston\"),\n",
    "    HumanMessage(content=\"Hi! I'm Faraz\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I lik venila ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    AIMessage(content=\"No problem\"),\n",
    "    HumanMessage(content=\"Having Fun?\"),\n",
    "    AIMessage(content=\"Yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)|prompt|model|output_parser\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "   \"messages\":messages+[HumanMessage(content=\"what math i have asked u\")],\n",
    "   \"language\":\"English\"\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You asked me:\\n\\n*  2 + 2  \\n\\n\\nLet me know if you have any other math problems you'd like me to solve!  ðŸ§® ðŸ˜„\\n\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with_chat_history = RunnableWithMessageHistory(chain,getSession,input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat9\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"I'm Faraz\")],\"language\":\"Englidh\"},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Faraz!  \\n\\nIs there anything I can help you with? \\n\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Faraz.  ðŸ˜Š I'm glad I could help!  Is there anything else I can do for you? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what is my name\")],\"language\":\"Englidh\"},\n",
    "    config=config\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
